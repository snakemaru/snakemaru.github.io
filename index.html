<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Bewaremypower">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Bewaremypower">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bewaremypower">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>Bewaremypower</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Bewaremypower</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/21/matlab参数估计函数/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="snakemaru">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Bewaremypower">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/21/matlab参数估计函数/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-21T15:36:16+08:00">
                2019-07-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <div id="sina_keyword_ad_area2" class="articalContent   newfont_family">
			<table border="1" cellspacing="0" cellpadding="0" width="901" style="width:675.6pt;border-collapse:collapse;border:none;mso-border-alt:solid windowtext .5pt; mso-yfti-tbllook:480;mso-padding-alt:0cm 5.4pt 0cm 5.4pt">
<tbody>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">函数名</span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border:solid windowtext 1.0pt; border-left:none;mso-border-left-alt:solid windowtext .5pt;mso-border-alt: solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">调用形式</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border:solid windowtext 1.0pt; border-left:none;mso-border-left-alt:solid windowtext .5pt;mso-border-alt: solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">函数说明</span></p>
</td>
</tr>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt; padding:0cm 5.4pt 0cm 5.4pt">
<p><span>binofit</span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span>PHAT=
binofit(X, N)</span></p>
<p><span>[PHAT,
PCI] = binofit(X,N)</span></p>
<p><span>[PHAT,
PCI]= binofit (X, N, ALPHA)</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">二项分布的概率的最大似然估计</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">置信度为</span><span>95%</span><span style="font-family:宋体;mso-ascii-font-family:">的参数估计和置信区间</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">返回水平α的参数估计和置信区间</span></p>
</td>
</tr>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt; padding:0cm 5.4pt 0cm 5.4pt">
<p><span>poissfit</span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span>Lambdahat=poissfit(X)</span></p>
<p><span>[Lambdahat, Lambdaci] = poissfit(X)</span></p>
<p><span>[Lambdahat, Lambdaci]= poissfit (X, ALPHA)</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">泊松分布的参数的最大似然估计</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">置信度为</span><span>95%</span><span style="font-family:宋体;mso-ascii-font-family:">的参数估计和置信区间</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">返回水平α的λ参数和置信区间</span></p>
</td>
</tr>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt; padding:0cm 5.4pt 0cm 5.4pt">
<p><span>normfit</span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span>[muhat,sigmahat,muci,sigmaci] =normfit(X)</span></p>
<p><span>[muhat,sigmahat,muci,sigmaci] = normfit(X,
ALPHA)</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">正态分布的最大似然估计，置信度为</span><span>95%</span><span style="font-family:宋体;mso-ascii-font-family:">的置信区间</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">返回水平α的期望、方差值和置信区间</span></p>
</td>
</tr>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt; padding:0cm 5.4pt 0cm 5.4pt">
<p><span>betafit</span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span>PHAT
=betafit (X)</span></p>
<p><span>[PHAT,
PCI]= betafit (X, ALPHA)</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">返回β分布参数</span><span>a</span><span style="font-family:宋体;mso-ascii-font-family:">和</span> <span>b</span><span style="font-family: 宋体;mso-ascii-font-family:">的最大似然估计</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">返回最大似然估计值和水平α的置信区间</span></p>
</td>
</tr>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt; padding:0cm 5.4pt 0cm 5.4pt">
<p><span>unifit</span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span>[ahat,bhat] = unifit(X)</span></p>
<p><span>[ahat,bhat,ACI,BCI] = unifit(X)</span></p>
<p><span>[ahat,bhat,ACI,BCI]=unifit(X, ALPHA)</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">均匀分布参数的最大似然估计</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">置信度为</span><span>95%</span><span style="font-family:宋体;mso-ascii-font-family:">的参数估计和置信区间</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">水平α的参数估计和置信区间</span></p>
</td>
</tr>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt; padding:0cm 5.4pt 0cm 5.4pt">
<p><span>expfit</span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span>muhat
=expfit(X)</span></p>
<p><span>[muhat,muci] = expfit(X)</span></p>
<p><span>[muhat,muci] = expfit(X,alpha)</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">指数分布参数的最大似然估计</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">置信度为</span><span>95%</span><span style="font-family:宋体;mso-ascii-font-family:">的参数估计和置信区间</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">水平α的参数估计和置信区间</span></p>
</td>
</tr>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt; padding:0cm 5.4pt 0cm 5.4pt">
<p><span>gamfit</span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span>phat
=gamfit(X)</span></p>
<p><span>[phat,pci]
= gamfit(X)</span></p>
<p><span>[phat,pci]
= gamfit(X,alpha)</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">γ分布参数的最大似然估计</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">置信度为</span><span>95%</span><span style="font-family:宋体;mso-ascii-font-family:">的参数估计和置信区间</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">最大似然估计值和水平α的置信区间</span></p>
</td>
</tr>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt; padding:0cm 5.4pt 0cm 5.4pt">
<p><span>weibfit</span></p>
<p><span>&nbsp;<wbr></span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span>phat =
weibfit(X)</span></p>
<p><span>[phat,pci]
= weibfit(X)</span></p>
<p><span>[phat,pci]
= weibfit(X,alpha)</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">韦伯分布参数的最大似然估计</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">置信度为</span><span>95%</span><span style="font-family:宋体;mso-ascii-font-family:">的参数估计和置信区间</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">返回水平α的参数估计及其区间估计</span></p>
</td>
</tr>
<tr>
<td width="95" valign="top" style="width:71.0pt;border:solid windowtext 1.0pt; border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt; padding:0cm 5.4pt 0cm 5.4pt">
<p><span>Mle</span></p>
</td>
<td width="345" valign="top" style="width:258.4pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span>phat =
mle('dist',data)</span></p>
<p><span>[phat,pci]
= mle('dist',data)</span></p>
<p><span>[phat,pci]
= mle('dist',data,alpha)</span></p>
<p><span>[phat,pci]
= mle('dist',data,alpha,p1)</span></p>
</td>
<td width="462" valign="top" style="width:346.2pt;border-top:none;border-left: none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt; mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt; mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt">
<p><span style="font-family:宋体;mso-ascii-font-family:">分布函数名为</span><span>dist</span><span style="font-family:宋体;mso-ascii-font-family:">的最大似然估计</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">置信度为</span><span>95%</span><span style="font-family:宋体;mso-ascii-font-family:">的参数估计和置信区间</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">返回水平α的最大似然估计值和置信区间</span></p>
<p><span style="font-family:宋体;mso-ascii-font-family:">仅用于二项分布，</span><span>pl</span><span style="font-family:宋体;mso-ascii-font-family:">为试验总次数</span></p>
</td>
</tr>
</tbody>
</table>							
		</div>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/15/adiff二进制代码检测/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="snakemaru">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Bewaremypower">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/15/adiff二进制代码检测/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-15T09:45:56+08:00">
                2019-07-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>###Abstract</p>
<p> 二进制代码检测常应用于补丁分析，剽窃检测，恶意软件分析和漏洞搜索之类。现有的解决方案在二进制代码导出的语法特征上的表现因为专业知识的存在而表现有所差异（往往有性能损失或者低检测精度）。并且由于跨版本二进制代码既在语法结构上有所差异，又在语义上有轻微偏差。现有解决方案之中很少有适用于跨版本二进制代码的。</p>
<p>  本文中提出了一种$\alpha$diff解法，采用三类语义特征来讨论这个问题。$\alpha$diff解法首先从每个二进制函数利用DNN生成intra-function feature，这个DNN直接作用于每个函数的原字节而不是专家提供的特征（比如语法结构）。$\alpha$diff还分析了每个二进制文本的function call graph，而它在跨版本二进制代码中是相对稳定的。$\alpha$diff从中提取了inter-function feature和inter-module feature。之后本文根据这三类特征定义了一种距离，并将其应用于BCSD。我们应用了$\alpha$diff的原型于2，5000，000个样本，结果表示$\alpha$diff相对其他BCSD方法效果平均超出10个百分点。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h3><p>  评估两个二进制文件之间是否相似的问题被称为BCSD（二进制代码相似性检测）。它在很多应用中有着重要作用，例如代码剽窃检测[32,33,43]，恶意软件系谱分析[2,26,28]。在应用于补丁前后版本的二进制文件使，它也能够被用于1day漏洞分析，或者用于导出漏洞特征。此外，应用于已知bug和目标应用时它能够用于cross-architecturebugsearching[16,17,52]。</p>
<p>  然而BCSD面临着某些挑战。首先，不同的编译器优化产生cross-optimization binaries。第二，不同算法的编译器（比如寄存器分配问题）生成cross compiler binaries。第三，不同平台产生cross-architecture binaries。这些二进制代码可能时语义相似的，但拥有不同的语法结构。另一方面，源代码本身根据时间可能会有修改（比如补丁），产生cross-version binaries。这些二进制代码当然时相似的，因为他们是同源的。但是他们拥有不同的语法结构和轻微不同的语义。现有的方案从某种程度上适用于这些问题，但是在cross-version binaries问题上表现较差。</p>
<p>  目前的BCSD问题解法主要依赖于CFG（comtrol flow graph），最常用的解法BinDiff利用了图形同构理论（GI）来比较函数的CFG。然而图形同构理论花费时间，缺乏多项式时间解。此外，GI对CFG改动非常敏感（即使是镜像操作），因此准确度很低。BinHunt和iBinHunt在GI的基础上引入了符号执行与污染分析来讨论这个问题，但是精确度也较低且需要先验条件。</p>
<p>  BinGo[6],Esh[12]andCABS[38]通过计算CGF部分相似度来构成全局相似度为CFG的改动提供了更多的弹性。DiscovRE[16]通过将一个filter作用于CFG来降低GI对比提供了更好的表现。它从CFG中获取了某些数字特征，比如计算basic blocks（BBs）的指令数目，并且通过KNN算法来预先过滤相似的CFG。Genius[17]从BBs中获取相似性数字特征，并且用他们来加强CFG顶点来获得 Attributed CFGs (ACFGs), 用以支持 cross-architecture BCSD.Gemini[52]使用一种端到端的神经网络来嵌入ACFGs,提供了更好的表现和精确度。</p>
<p>  这些解决方案全都依赖于语法特征比如CFG。这些特征是由专业知识提供的，有时会引入bias。比如CFG可能在代码没有变化或者镜像变化时改变，造成BCSD结果中的可见偏差。本文中首先讨论的问题是：RQ1: How to extract features from binary code with as little human bias as possible?</p>
<p>  很少有解决方案考虑了二进制代码的语义特征，除了BinGo[6]和Esh[12].这两种方法使用算法检查CFG片段的语义相似性，因此是花费时间的。从另一方面看，跨版本二进制代码的语义可能有轻微改动（比如打补丁），因此严格的相似性比较是不合适的。本文讨论的第二个问题是：RQ2: How to efficiently utilize semantic features to improve the accuracy of BCSD? </p>
<p>  跨版本二进制一直在被迫切需求（比如信息传输和补丁分析方面）。它也是BinDiff提供的最有吸引力的应用之一。然而这个问题目前远远没有被解决。比如说BinDiff在比较上百二进制问题件的coreutils5.0和coreutils8.29时的平均精确度不到0.5。但是研究者往往不注重这个特例。本文讨论的第三个问题是：RQ3:Howtobuild a solution fit for cross-version BCSD? </p>
<p>  本文中提供了一种$\alpha$diff方法来讨论前述问题。简短来说，它获取了二进制代码的语义特征，并且用他们来计算相似分数来应用BCSD。为了适用于跨版本二进制代码，所有的二进制函数都被三个语义特征标记：the function code’s(i.e., intra-function)features,function invocation(i.e.,inter-function) features,and module interactions (i.e.,inter-module)features. </p>
<p>  首先，为了提取intra-function feature，我们不适用CFG或者其他的专家知识，而是直接用神经网络来从二进制源码中获取无偏差知识。因此我们受先前工作[45]的启发，应用神经网络获取特征。此外我们将源码表示为矩阵，应用CNN来转化其为embedding。此外，为了保证相似函数的embedding足够接近，我们将这个CNN嵌入孪生网络。</p>
<p>   第二，我们发现相似的函数拥有相似的call graph，因此我们分析各个函数的函数调用图来导出他们的inter-function feature。理想情况下所有函数调用图都应当被考虑，但是在我们的方案中出于表现考虑，我们只使用函数顶点在调用图中的出度和入度。</p>
<p>  第三，我们还发现相似的函数有相似的imported function（即使是在不同的架构下）。因此我们分析每个函数的导入函数集合，并且将其视为inter-module feature。</p>
<p>  特定的算法（section 3.4）被应用于将这个集合转化为向量，来应用于距离计算。</p>
<p>  因此，给定两个二进制函数，我们可以导出他们的intra-function,inter-function 和 inter-module 特征。之后我们可以计算每对特征之间的距离。最终我们可以利用这三类距离计算两个函数的全局相似度。</p>
<p>  我们应用了$\alpha$diff的原型于拥有将近2，500，000对跨版本函数大小的数据集上评估，它们从开源代码库取得。结果显示，$\alpha$diff平均优于BinDiff11%，对某些二进制对的表现高达52%。只考虑intra-function feature， $\alpha$Diff 比BinDiff表现平均高出6%，对某些二进制对的表现高达43%。</p>
<p>  更重要的是，即使我们的训练集由跨版本二进制代码组成，我们的模型对cross-compiler 和cross-architecture二进制代码检测也适应良好，即使在特定的应用中（比如漏洞搜索）。结果显示$\alpha$diff比目前现有的方案优良。</p>
<p>  总的来看，我们做了以下几点工作：</p>
<ul>
<li>我们将神经网络应用于原二进制文件来导出函数内语义特征而不依赖于专业知识。同时，将其与函数间语义特征和模块语义特征相结合，我们构造了端到端的对于BCSD问题的$\alpha$diff解法。</li>
<li>我们构建了应用于深度学习的有标签数据集，包含66，823对二进制文件和接近2，5000，000对函数对。研究者可以随意应用这些数据。</li>
<li>我们开发了$\alpha$diff的原型，并在这些数据上进行评价。结果显示相比目前现有的解法，在cross-compiler,cross-architecture和 cross-version BCSD问题上它的表现都更好。</li>
</ul>
<h3 id="2-Problem-Definition"><a href="#2-Problem-Definition" class="headerlink" title="2.Problem Definition"></a>2.Problem Definition</h3><p>在这个模块我们将讨论BCSD问题的定义。</p>
<h4 id="2-1Notation-and-Assumption"><a href="#2-1Notation-and-Assumption" class="headerlink" title="2.1Notation and Assumption"></a>2.1Notation and Assumption</h4><p>我们假设所有的二进制代码都由高级语言编译而来，不包含手写代码和封装器的生成，用于避免二进制混淆。为了实际应用，我们也假设二进制文件中的调试符号已经被移除，他它们会使二进制代码分析更加困难。</p>
<p>二进制文件$B_i$ 包含函数集合$f_{i1},f_{i2},…,f_{in}$。二进制函数的定义，现有的方案已经非常成熟，本文不再赘述。我们现在假定所有的二进制函数都能被正确定义，即所有$B_i$中的函数$f_{ij}$的所有字节都是已知的。</p>
<p>BCSD问题中的一个重要任务就是找到所有函数中的对应部分。两个二进制函数在由同名函数编译而来（包括命名空间和类），并且在同样的语言环境中使用时被认为是相似的。值得注意的是，完全相同的函数是匹配的，但是匹配函数不一定是完全相同的。</p>
<p>2.2Cross-version BCSD Problem</p>
<p>跨版本二进制问题着眼于分析两个由同一源码项目编译而来（可能会随时间有所改进）的二进制文件$B_1$和$B_2$。它与以下问题有关：</p>
<ul>
<li>function matching:对$B_1$中的每个函数$f_{1i}$，如果存在，找到对应$B_2$中的函数$f_{2j}$</li>
<li>similarity score:对每对函数对$f_{1i}$和$f_{2j}$，计算0到1之间的语义相似度数值，来表示它们之间的相似程度。</li>
<li>difference identification：对每对匹配函数对$f_{1i}$和$f_{2j}$确认它们的代码字节之间的不同之处，如果它们的相似度指标比1小。</li>
</ul>
<p>在本文中我们只关注前两个问题</p>
<h4 id="2-3Variant-BCSD-Problems"><a href="#2-3Variant-BCSD-Problems" class="headerlink" title="2.3Variant BCSD Problems"></a>2.3Variant BCSD Problems</h4><p>本文中我们致力于解决相较其他问题更加困难的跨版本BCSD问题，从评估结果来看，我们的解决方案可以直接应用于以下几类变种情形并得到较好的结果：</p>
<ul>
<li>Cross-optimization BCSD:它致力于分析两个从同样代码、使用相同编译器但是使用不同编译优化编译而来的二进制文件。</li>
<li>Cross-compiler BCSD：致力于分析使用不同编译器对同样代码编译产生的二进制文件。</li>
<li>Cross-architecture BCSD：致力于分析链接到不同架构的同一源码编译而来的二进制代码，比如说拥有不同的指令集。</li>
</ul>
<h4 id="2-4Evaluation-Metric"><a href="#2-4Evaluation-Metric" class="headerlink" title="2.4Evaluation Metric"></a>2.4Evaluation Metric</h4><p>BCSD方案的目标是精确辨别匹配函数。我们通过计算匹配函数是否在BCSD结果的前K个中来评估模型，与相关工作[29,47]中的做法相似。</p>
<p>给定两个二进制文件$B_1 = f_{11}, f_{12},…,f_{1n}$,和$B_2 = f_{21},f_{22},…,f_{2m}$。为了简化问题，我们假设其中有T对函数对，记为$(f_{11},f_{21}),(f_{12},f_{22}),…,(f_{1T},f_{2T})$。剩下的函数对不匹配。</p>
<p>对于$B_1$中的任意函数$f_{1i}$，BCSD方案根据$B_2$中函数对于$f_{1i}$的相似性将$B_2$中的函数排序。我们定义前K个函数为$topK(f_{1i})$,并且定义$hit@K(f_{1i})$为$f_{1i}$的匹配函数是否在$topK(f_{1i})$<br>$$<br>hit@K(f_{1i})=\left{<br>\begin{aligned}<br>&amp;1,f_{2i}\in topK(f_{1i})and i \leq T\<br>&amp;0,otherwise<br>\end{aligned}<br>\right.<br>\tag{1}<br>$$<br>BCSD的评估量定义如下<br>$$<br>Recall@K(B_1,B_2)=\frac{\sum_{i=1}^{T}hit@K(f_{1i})}{T}<br>\tag{2}<br>$$</p>
<h3 id="3-Approach"><a href="#3-Approach" class="headerlink" title="3.Approach"></a>3.Approach</h3><h4 id="3-1Overview"><a href="#3-1Overview" class="headerlink" title="3.1Overview"></a>3.1Overview</h4><p>传统的基于语法特征的解决方案不足以分析跨版本BCSD问题，跨版本二进制函数之间的相似程度应当被它们的语义特征衡量，比如它们的原文本、和同一二进制文件中其他函数之间的关系、和模块中导入的函数之间的关系。简单来所，我们把这些特征定义为intra-function,inter-function 和inter-module-feature。</p>
<p>和使用CFG或者其他的传统方案不同，我们使用DNN获取语义特征，使用call graph（CG）获取inter-function 和inter-module-feature。后两者也可以从传统方案获取。</p>
<p>网络的总体结构如图Figure1。</p>
<p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563292143909.png" alt="1563292143909"></p>
<h4 id="3-2Intra-function-Semantic-Feature"><a href="#3-2Intra-function-Semantic-Feature" class="headerlink" title="3.2Intra-function Semantic Feature"></a>3.2Intra-function Semantic Feature</h4><p>受到之前二进制分析解法[45]的启发，我们同样使用神经网络从源码字节中来导出intra-function语义特征。在多次尝试后，我们发现卷积神经网络（CNN）最适用。</p>
<p>在我们的方案中，CNN以函数$I_q$的原字节作为输入，并且将他们映射到函数嵌入$f(I_q)$（d维欧几里得空间下的向量），之后我们可以通过两个函数的函数嵌入计算两个函数之间的距离。</p>
<p>为了检测相似性，我们需要训练模型来符合以下特征：RQ：两个相似函数之间的距离需要尽量小，而两个相异函数之间的距离需要尽量大。</p>
<p>受到深度度量学习的启发[3,44,47]，我们同样将两个CNN应用于孪生神经网络，来适应RQ并训练CNN的参数。同Gemini[52]方案不同，我们从DNN生成的embedding以某些工程语法特征为基础，不需要专家知识，并且适用于跨版本BCSD。</p>
<h5 id="3-2-1Embedding-Function-with-CNN"><a href="#3-2-1Embedding-Function-with-CNN" class="headerlink" title="3.2.1Embedding Function with CNN"></a>3.2.1Embedding Function with CNN</h5><p>卷积神经网络（CNN）是一种应用于网格拓扑结构的已知数据的网络。现在已经在很多应用方面有了巨大成功。</p>
<p>然而传统的CNN是专门为了图像分类而实际的，需要和RGB图像格式相似的输入，即至少有三个通道。这不适用于我们的问题，因此在多次尝试后，我们设计CNN如下：</p>
<ul>
<li><p>网络结构：我们的CNN拥有8个卷积层，8个分批规范化层，4个最大池化层，和两个全连接层。整个模型使用修正线性单元（ReLU）来作为非线性激活函数。网络中总共有多于1，6000个参数。</p>
</li>
<li><p>网络IO：CNN使用$100<em>100</em>1$的张量T作为输入，输出64维向量。我们将函数的原字节依照字节顺序存入张量T，如果函数少于10000字节，我们以0字节来补充，如果函数多于10000字节，我们舍弃剩余的字节。</p>
<p>值得注意的是，很少有函数多于10000个字节（少于0.01%）。此外，如果函数的前10000个字节是不相似的，这两个函数也更可能是不相似的。因此舍弃剩余的字节是可行的。</p>
</li>
<li><p>Data augmention</p>
<p>在图像分类应用中，数据增强是一种用于改进CNN训练数据集的常用方法。但是与图像像素不同，函数字节对于改变更加敏感，由于改变往往改动了函数的语义。因此在训练我们的模型时，我们不应用数据增强。</p>
</li>
<li><p>Overfitting issue</p>
<p>我们同样考虑AlexNet中使用的手段（比如层堆叠方式），来避免模型过拟合。在实际应用中，我们使用分批规范化来讨论过拟合问题。</p>
</li>
</ul>
<h5 id="3-2-2Learning-Parameters-Using-Network"><a href="#3-2-2Learning-Parameters-Using-Network" class="headerlink" title="3.2.2Learning Parameters Using Network"></a>3.2.2Learning Parameters Using Network</h5><p>为了训练CNN嵌入网络中的参数。我们使用孪生神经网络结构[4]，如图Figure2中所示。这个孪生神经网络以两个CNN嵌入，每个CNN以一个函数作为输入，记为$I_q$和$I_t$，并且输出相应的函数嵌入，记为$f(I_q;\theta)$和$f(I_t;\theta)$，这里$f$表现的是网络的结构而$\theta$表示网络的参数。</p>
<p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563292759925.png" alt="1563292759925"></p>
<p>除了输入函数对$(I_q,I_t)$之外，孪生网络还引入输入$y$，输入$y$是表现两个函数$I_q$,$I_t$是否相似的物理量。如果它们相似，$y=1$否则$y=0$。</p>
<p>训练的目标是找到满足实现给定条件的最优的参数$\theta$，也就是让相似函数之间的距离尽量小而相异函数之间的距离尽量大。</p>
<p>两个函数之间的intra-function features定义如下：<br>$$<br>D1(I_q,I_t)=\lvert f(I_q;\theta)-f(I_t;\theta)\lvert<br>\tag{3}<br>$$<br>为了达到这个目标，我们定义对比损失函数如下：</p>
<p>$$<br>L(\theta)=\mathop{Average}_{(I_q,I_t)}<br>\lbrace<br>y\cdot D1(I_q,I_t)+(1-y)\cdot max(0,m-D1(I_q,I_t))<br>\rbrace<br>\tag{4}<br>$$<br>$m$是一个预先给定的常参数，即相异函数之间的最短距离。</p>
<p>我们可以发现，如果这个损失函数取小值，那么$D1(I_q,I_t)$就是在$y=1$时趋近于0，而$max(0,m-D1(I_q,I_t))$就是在$y=0$时趋近于0的。简单来说就是经过变换之后的每个函数的embedding在空间中都是与相似函数相近而与相异函数距离远的。因此之前的要求能够被满足。</p>
<p>现在模型的训练目标被转化为寻找参数$\theta$来使孪生网络的损失函数取最小。这个问题能使用应用回溯算法的StochasticGradient Descent(SGD)来解决[31,41]。</p>
<ol start="3">
<li><h5 id="2-3Negative-Training-Samples"><a href="#2-3Negative-Training-Samples" class="headerlink" title="2.3Negative Training Samples"></a>2.3Negative Training Samples</h5></li>
</ol>
<p>构造合适的正采样和负采样对模型训练是重要的，如果想让CNN的损失函数收敛。</p>
<p>与[37,44,47]中的工作相似，我们选择从训练中的每个mini-batch中，利用正采样来生成负采样。</p>
<p>对mini-batch中每对样例$(I_q,I_t)$，我们生成两个semi-hard 的负样本。记为$(I_q,I_{n1})$和$(I_p,I_{n2})$。以函数$I_q$为例，我们寻找函数$I_n$来满足公式<br>$$<br>0&lt;D1(I_q,I_n)&lt;m<br>\tag{6}<br>$$<br>我们随机选择函数$I_{n1}$来作为满足这个约束的负样本。但是我们舍弃那些强的负样本（比如使$D1(I_q,I_n)$最小的那些），因为这些样本可能使模型导向局部最优解。</p>
<p>为了获取足够多的负样本，我们在每次每次训练中轮换mini-batch。即在每次训练中我们随机排序二进制文件，然后再随机排序每对二进制文件中的函数对（正样本）。这些随机排序的正样本将之后被分为mini-batch并生成新的负样本。</p>
<h4 id="3-3Inter-function-Semantic-Feature"><a href="#3-3Inter-function-Semantic-Feature" class="headerlink" title="3.3Inter-function Semantic Feature"></a>3.3Inter-function Semantic Feature</h4><p>函数并不单独工作，它们需要调用其他函数或者被其他函数调用。这种同一二进制文件中函数与其他函数之间的相互关系是重要的语义特征。这种特征能够使用call graph表示。我们发现相似的函数拥有相似的调用图。</p>
<p>理想情况下函数的总体调用图需要被考虑。比如说SMIT[26]使用了调用图匹配来检测恶意软件之间的相似性。虽然它们使用了有效的图编辑算法，计算时间对于实际应用仍然显得过长。</p>
<p>在我们的使用中我们只导出图的顶点出入度来作为它的inter-function feature。即对每个函数$I_q$我们将其的inter-function feature转化为二维向量：<br>$$<br>g(I_q)= (in(I_q),out(I_q))<br>\tag{7}<br>$$<br>这里$in(I_q)$和$out(I_q)$是函数顶点$I_q$在调用图中的入度和出度。两个函数inter-function feature之间的欧几里得距离定义如下：<br>$$<br>D2(I_q,I_t)=\lvert g(I_q)-g(I_t)\rvert<br>\tag{8}<br>$$</p>
<h4 id="3-4Inter-module-Semantic-Feature"><a href="#3-4Inter-module-Semantic-Feature" class="headerlink" title="3.4Inter-module Semantic Feature"></a>3.4Inter-module Semantic Feature</h4><p>每个函数$I_q$有定义在默认模块中的模块调用函数集合，定义为$imp(I_q)$。我们发现相似的函数拥有相似的模块导入函数。此外，由于模块化开发的存在，集合$imp(I_q)$在版本变化中是趋于稳定的。模块调用函数集合也是重要的语义特征，我们把它记作inter-module feature。</p>
<p>出于连续性考虑，我们同样将inter-function feature转化为向量来进行距离计算。我们使用元素检测公式来将一个集合嵌入超集空间。<br>$$<br>h(set,superset)=&lt;x_1,x_2,…,x_N&gt;<br>\tag{9}<br>$$<br>对两个函数$I_q$和$I_t$，假设它们所在的二进制文件是$B_q$和$B_t$，我们记它们的模块导入函数集合为$imp(B_q)$和$imp(B_t)$。之后我们将超集取为$imp(B_q)\bigcap imp(B_t)$。并用公式计算inter-function feature之间的距离如下：<br>$$<br>D3(I_q,I_t)=\lvert h(imp(I_q),imp(B_q)\bigcap imp(B_t))-h(imp(I_t),imp(B_q)\bigcap imp(B_t))\rvert<br>\tag{10}<br>$$<br>值得注意的是，$imp(B_q)$是$imp(I_q)$的超集，而$imp(B_t)$是$imp(I_t)$的超集。此外，即使函数名之类的符号可能已经从二进制文件中被剔除，模块调用函数名将一直随着模块之间的链接而存在。因此提取这种特征是较为容易的。</p>
<p>3.5Overall Similarity Computation</p>
<p>给定两个函数$I_q$和$I_t$，我们可以计算它们之间三个特征的距离$D1、D2、D3$。如前文所述，因为两个相似函数之间的模块函数调用和语义特征都是相似的，因此$D1、D3$较小，其中相似函数之间的$D1$是一定小于$m$的。但是由于跨版本二进制代码拥有不同函数调用图，尤其是对于图中函数顶点的出入度，因此$D2$可能较大。</p>
<p>因此我们计算全局距离如下来表示两个函数之间的相似程度：<br>$$<br>D(I_q,I_t)=D1(I_q,I_t)+(1-\xi^{D2(I_q,I_t)})+D3(I_q,I_t)<br>\tag{11}<br>$$<br>这里$\xi$是事先定义的$(0,1)$区间内的常参数，用来限制D2的影响。</p>
<p>对问题中的每个函数$I_q$我们将计算它和目标函数之间的全局距离，之后将目标函数按照全局距离的大小排序。其中最近的目标函数将更可能和$I_q$相似。</p>
<h3 id="4-Evaluation"><a href="#4-Evaluation" class="headerlink" title="4.Evaluation"></a>4.Evaluation</h3><h4 id="4-1Implementation"><a href="#4-1Implementation" class="headerlink" title="4.1Implementation"></a>4.1Implementation</h4><p>我们实施了$\alpha$diff方法的原型，它包含三个方面：预处理、特征生成、神经网络模型。预处理作为IDAPro6.8[24]的嵌入执行。对二进制文件中的每个函数，三种信息被导出，如section3中。最终原码被输入网络转化为函数嵌入，网络模型在TensorFlow-1.3[1]andKeras-2.0[8].环境中实施。</p>
<h4 id="4-2Evaluation-Setup"><a href="#4-2Evaluation-Setup" class="headerlink" title="4.2Evaluation Setup"></a>4.2Evaluation Setup</h4><p>我们的实验在配备两个2.20GHz的IntelXeonE5-2650v4CPU（共 24核）、128G内存、12TB硬盘、配有四张4NVIDIATeslaP100PCIE16G显卡的服务器上进行。在本次实验中只使用了一张显卡。</p>
<h5 id="4-2-1dataset"><a href="#4-2-1dataset" class="headerlink" title="4.2.1dataset"></a>4.2.1dataset</h5><p>我们需要数据集来训练神经网络和评估模型。我们从66，823份X86 Linux平台下收集了2，489，793对正样本（函数对）。如同Table1中显示，这个数据集有两份来源。</p>
<p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563353633133.png" alt="1563353633133"></p>
<p>第一个来源是GitHub仓库，我们收集了31份项目的9419次发布的源码，所有的发布都由GCC-5.4采用默认优化算法编译。我们将每个项目的两次发布二进制配对，得到共8，510对。</p>
<p>第二个来源是Debian的包仓库，我们直接从.deb包中获取源码。我们从Ubuntu12.04、14.04、16.04下得到了895个包的合计1，842个版本。我们将每个版本的二进制代码和它们的最近版本匹配，共得到58，313对。</p>
<p>对于每对跨版本二进制文件，我们检索成对匹配函数，它们具有相同的名称但不相同。为了增加多样性，我们还提取了一些函数，它们在跨版本二进制文件中是相同的。 最后，我们总共有2,489,793跨版本匹配函数，来自66,823成对的跨版本二进制文件。 其中，约1.52％成对的跨版本函数是相同的。值得注意的是，BinDiff的结果显示，29.4％的对是相同的，这是由于基于GI的算法中引入的不准确性。</p>
<p>Ground Truth 如同前文所说，为了得到匹配函数的正确标注，我们利用函数名，因此依赖于函数二进制文件中可能有的调试符号。对于GitHub代码，编译选项-g在编译时被添加。对Debian包仓库，我们只手机那些符号文件，收集好这些标注之后，我们剥离了二进制文件中的所有调试符号，并在处理之后的数据上评估我们的模型。</p>
<h5 id="4-2-2DatasetSplit"><a href="#4-2-2DatasetSplit" class="headerlink" title="4.2.2DatasetSplit"></a>4.2.2DatasetSplit</h5><p>我们将数据集分为三个不相交的集合，分别用于训练、测试和评价。为了评估训练模型对于新二进制文件的效果，我们将三个集合中的正样本比例设为4：1：1 。见Table1。</p>
<h5 id="4-2-3Neural-Network-Training"><a href="#4-2-3Neural-Network-Training" class="headerlink" title="4.2.3Neural Network Training"></a>4.2.3Neural Network Training</h5><p>In the CNN model, we use the RMSProp optimizer [25], set the learning rate to 0.001, and set the forgetting factor to 0.9. In the Siamese network (Eq.4), we set the margin m, i.e., the minimal distance between dissimilar functions, to 1.0. Furthermore, we set the ξ in the overall similarity score formula (e.g., Equation 11) to 0.75. For each mini-batch, 100 positive samples are selected and 200 semihard negative samples are generated online. The Siamese network is trained for 200 epochs (3.075 h/epoch), to tune the parameters in the CNN embedding network.</p>
<h4 id="4-3-Hyper-parameters-in-the-Siamese-Network"><a href="#4-3-Hyper-parameters-in-the-Siamese-Network" class="headerlink" title="4.3 Hyper-parameters in the Siamese Network"></a>4.3 Hyper-parameters in the Siamese Network</h4><p>受限于时间和资源影响，我们每次训练使用25%样本，30epochs。我们在正样本不少于100的测试集合上评估。</p>
<h5 id="4-3-1-Input-Shape-and-Convolutional-Layer-Type"><a href="#4-3-1-Input-Shape-and-Convolutional-Layer-Type" class="headerlink" title="4.3.1 Input Shape and Convolutional Layer Type"></a>4.3.1 Input Shape and Convolutional Layer Type</h5><p>（Recall@1下的评估如下</p>
<p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563357648100.png" alt="1563357648100"></p>
<p>得到的结论：</p>
<ul>
<li>1D-CNN效果不如2D，但是原因未知</li>
<li>embedding的大小在64维时表现最好</li>
<li>对负采样方式，$\alpha$diff-4tuple效果最好</li>
<li>对网络结构，4tuple孪生网络效果最好</li>
</ul>
<h5 id="4-4-1-Evaluation-on-Testing-Set"><a href="#4-4-1-Evaluation-on-Testing-Set" class="headerlink" title="4.4.1 Evaluation on Testing Set"></a>4.4.1 Evaluation on Testing Set</h5><p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563358114375.png" alt="1563358114375"></p>
<h5 id="4-4-2Evaluation-on-coreutils"><a href="#4-4-2Evaluation-on-coreutils" class="headerlink" title="4.4.2Evaluation on coreutils"></a>4.4.2Evaluation on coreutils</h5><p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563358186885.png" alt="1563358186885"></p>
<h4 id="4-5-Performance-in-Cross-compiler-BCSD"><a href="#4-5-Performance-in-Cross-compiler-BCSD" class="headerlink" title="4.5 Performance in Cross-compiler BCSD"></a>4.5 Performance in Cross-compiler BCSD</h4><p>Cross-compiler BCSD has three sub-types:</p>
<ul>
<li>cross-compiler-vendor</li>
<li>cross-compiler-version </li>
<li>cross-optimization-level. </li>
</ul>
<h5 id="4-5-1-Cross-compiler-vendor-amp-Cross-compiler-version"><a href="#4-5-1-Cross-compiler-vendor-amp-Cross-compiler-version" class="headerlink" title="4.5.1 Cross-compiler-vendor &amp; Cross-compiler-version."></a>4.5.1 Cross-compiler-vendor &amp; Cross-compiler-version.</h5><p>六种漏洞项目下的表现：compiled the pre-patch version with gcc-4.6.3,<br>and compiled the post-patch version with clang-3.8. </p>
<p>两个实验：</p>
<ul>
<li>查询补丁文件中的漏洞：如果返回了漏洞或者漏洞在top1，则√否则×</li>
<li>检查全局精确度：即Recall@1和MRR</li>
</ul>
<p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563358389234.png" alt="1563358389234"></p>
<h5 id="4-5-2-Cross-compiler-vendor-amp-Cross-optimization-level"><a href="#4-5-2-Cross-compiler-vendor-amp-Cross-optimization-level" class="headerlink" title="4.5.2 Cross-compiler-vendor &amp; Cross-optimization-level."></a>4.5.2 Cross-compiler-vendor &amp; Cross-optimization-level.</h5><p>we compiled coreutils for x86 32-bit and x86 64-bit architectures, using gcc (v4.8.2) and clang (v3.0) with various optimization levels (O0 to O3)</p>
<p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563359083466.png" alt></p>
<p>Figure5中我们将COREUTILS中不同架构下编译的二进制进行匹配。其中C32 − G64 means that, when querying functions compiled using clang for x86 architecture, around 42% of their matching functions compiled using gcc for x64 architecture are ranked 1 by the tool BinGo, while 46% are ranked 1 by αDiff。</p>
<p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563359155550.png" alt="1563359155550"></p>
<h3 id="4-7-Application-in-Vulnerability-Search"><a href="#4-7-Application-in-Vulnerability-Search" class="headerlink" title="4.7 Application in Vulnerability Search"></a>4.7 Application in Vulnerability Search</h3><p>We first compiled the vulnerable OpenSSL library, which have<br>two virtually identical vulnerabilities TLS and DTLS, on platforms<br>ARM, MIPS and x86。</p>
<p>$\alpha$diff总能将匹配函数放在1-2位，总的来看它的效果优于其他方法。</p>
<p>由于Gemini引入了专家知识，我们认为其有偏差，不进行比较。</p>
<p><img src="C:\Users\谐波分量\AppData\Roaming\Typora\typora-user-images\1563359634747.png" alt="1563359634747"></p>
<h3 id="5-Discussion"><a href="#5-Discussion" class="headerlink" title="5.Discussion"></a>5.Discussion</h3><ul>
<li>无法得知为何2D-CNN的表现比1D-CNN要好</li>
<li>函数调用图和函数模块调用的特征在我们的评估中占比很大，我们将来会考虑使用跨架构数据集来实验。</li>
</ul>
<h3 id="6-Related-work"><a href="#6-Related-work" class="headerlink" title="6.Related work"></a>6.Related work</h3><p>在本节中，我们简要地调查了密切相关的工作。</p>
<h4 id="6-1二进制代码相似性分析"><a href="#6-1二进制代码相似性分析" class="headerlink" title="6.1二进制代码相似性分析"></a>6.1二进制代码相似性分析</h4><ul>
<li><h6 id="Staitic-Analysis"><a href="#Staitic-Analysis" class="headerlink" title="Staitic Analysis."></a>Staitic Analysis.</h6><p> BinDiff [55]，DiscovRE [16]和Genius [17]基于CFG / CG图同构（GI）理论[14,18]。 DiscovRE [16]标识了一组轻量级的数字特征和根据功能构建预过滤器，以快速识别小型候选功能集。 Genius [17]将CFG编码为高级数值向量，以实现实时漏洞搜索大量的固件映像。这些方法取决于图表匹配，没有已知的多项式时间算法，同时忽略具体汇编级指令的语义。<br>受DiscovRE和Genius的启发，Gemini [52]假设一个函数可以表示为ACFG，一个带有数字属性的CFG。它通过孪生结构和Structure2vec [11]网络将每个ACFG转换为嵌入式，这与我们的方法相似。但是，Gemini依赖于手动调整的特征，例如CFG结构和数字特征。 $\alpha$Diff从函数的原始字节中提取特征，没有人为干扰。<br>BinHunt [19]和iBinHunt [34]通过符号执行和污点分析来扩展GI，以找到语义差异。 BinGo [6]通过选择性内联捕获完整的函数语义然后利用长度改变的迹线进行对未知二进制函数的建模。 Esh [12]通过计算较小片段的函数相似性获得全局相似性。这些方法在计算上很昂贵。例如，Esh需要平均3分钟比较一对功能。</p>
</li>
<li><h6 id="Dynamic-Analysis"><a href="#Dynamic-Analysis" class="headerlink" title="Dynamic Analysis"></a>Dynamic Analysis</h6><p>假设代码在运行时行为相似，BELX [15]在某些调用文本中执行每对函数，并在受控随机环境下收集函数的运行时行为。 IMF-SIM [49]引入内存模糊来解决动态方法的覆盖问题。这些方法依赖于特定于体系结构用于执行或模拟二进制文件的工具，并且不方便应用。</p>
</li>
</ul>
<h4 id="6-2深度度量学习"><a href="#6-2深度度量学习" class="headerlink" title="6.2深度度量学习"></a>6.2深度度量学习</h4><p>Bromley等人。 [4]为深度度量学习和学习铺平了道路，并训练了孪生网络用于签名验证。 （比如Chopra）[9]提出了一种从数据中训练相似性度量的方法并将其应用于面部验证。 [3]利用深度卷积网络和孪生网络学习了fine-grained<br>visual similarity。FaceNet [44]使用深度卷积网络和 triplet embedding [51] 学习了面部特征的嵌入以进行面部验证和识别。与之相反有contrastive embedding [22]和triplet embedding [51]。[47]提出了一种充分利用分批优化的新的深度特征嵌入算法。</p>
<h4 id="6-3卷积神经网络"><a href="#6-3卷积神经网络" class="headerlink" title="6.3卷积神经网络"></a>6.3卷积神经网络</h4><p>卷积网络是一种专门用于处理数据的神经网络，具有已知的网格状拓扑结构[20,31]。 CNN通常由多个交错层组成卷积，非线性激活，局部响应归一化，池化层和一个或多个完全连接的层。自从AlexNet [30]在ILSVRC2012 [42]中取得了显着成功，已有很多人对CNN和其变种感兴趣，例如VGGNet [46]，Inception-v3 [48]和ResNet [23]。更多信息可以在[20,21,54]中找到。</p>
<p>### </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">snakemaru</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">snakemaru</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
